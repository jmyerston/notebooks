{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load relation_extraction_depmatcher.py\n",
    "# relation_extraction_depmatcher.py v 0.5\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import streamlit as st\n",
    "import random\n",
    "import numpy\n",
    "from collections import Counter\n",
    "from spacy.matcher import DependencyMatcher\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List\n",
    "from spacy.pipeline import merge_entities\n",
    "import csv\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "nlp.add_pipe(merge_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_doc(doc):\n",
    "    #displacy.render(doc, style=\"dep\", options={\"distance\": 120}, jupyter=True)\n",
    "    #displacy.render(doc, style=\"ent\", options={\"distance\": 120}, jupyter=True)\n",
    "    options = {\"compact\": True, \"add_lemma\": True, \"collapse_phrase\": True}\n",
    "    displacy.render(doc, style=\"dep\", options=options)\n",
    "    displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_subtrees(doc, subtrees):\n",
    "\n",
    "    words = [{\"text\": t.text, \"tag\": t.pos_} for t in doc]\n",
    "\n",
    "    if not isinstance(subtrees[0], list):\n",
    "        subtrees = [subtrees]\n",
    "\n",
    "    for subtree in subtrees:\n",
    "        arcs = []\n",
    "\n",
    "        tree_indices = set(subtree)\n",
    "        for index in subtree:\n",
    "\n",
    "            token = doc[index]\n",
    "            head = token.head\n",
    "            if token.head.i == token.i or token.head.i not in tree_indices:\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                if token.i < head.i:\n",
    "                    arcs.append(\n",
    "                        {\n",
    "                            \"start\": token.i,\n",
    "                            \"end\": head.i,\n",
    "                            \"label\": token.dep_,\n",
    "                            \"dir\": \"left\",\n",
    "                        }\n",
    "                    )\n",
    "                else:\n",
    "                    arcs.append(\n",
    "                        {\n",
    "                            \"start\": head.i,\n",
    "                            \"end\": token.i,\n",
    "                            \"label\": token.dep_,\n",
    "                            \"dir\": \"right\",\n",
    "                        }\n",
    "                    )\n",
    "        print(\"Subtree: \", subtree)\n",
    "        # displacy.render(\n",
    "        displacy.serve(\n",
    "            {\"words\": words, \"arcs\": arcs},\n",
    "            style=\"dep\",\n",
    "            options={\"distance\": 120},\n",
    "            manual=True,\n",
    "            #jupyter=True\n",
    "        )\n",
    "\n",
    "PTB_BRACKETS = {\n",
    "    \"-LRB-\": \"(\",\n",
    "    \"-RRB-\": \")\",\n",
    "    \"-LCB-\": \"{\",\n",
    "    \"-RCB-\": \"}\",\n",
    "    \"-LSB-\": \"[\",\n",
    "    \"-RSB-\": \"]\",\n",
    "}\n",
    "\n",
    "def clean_and_parse(sent: str, nlp):\n",
    "\n",
    "    tokens = sent.strip().split(\" \")\n",
    "\n",
    "    new = []\n",
    "\n",
    "    for token in tokens:\n",
    "        new_token = PTB_BRACKETS.get(token, None)\n",
    "        if new_token is None:\n",
    "            new.append(token)\n",
    "        else:\n",
    "            new.append(new_token)\n",
    "\n",
    "    return nlp(\" \".join(new))\n",
    "\n",
    "\n",
    "def parse_dep_path(dep_string: str):\n",
    "\n",
    "    rules = [rule.split(\"|\") for rule in dep_string.split(\" \")]\n",
    "\n",
    "    for triple in rules:\n",
    "\n",
    "        if triple[0] in PTB_BRACKETS:\n",
    "            triple[0] = PTB_BRACKETS[triple[0]]\n",
    "\n",
    "        if triple[2] in PTB_BRACKETS:\n",
    "            triple[2] = PTB_BRACKETS[triple[2]]\n",
    "\n",
    "        if triple[1] == \"nsubj:xsubj\":\n",
    "            triple[1] = \"nsubj\"\n",
    "\n",
    "        if triple[1] == \"nsubjpass:xsubj\":\n",
    "            triple[1] = \"nsubjpass\"\n",
    "    return rules\n",
    "\n",
    "\n",
    "def check_for_non_trees(rules: List[List[str]]):\n",
    "\n",
    "    #print(\"reglas\", rules)\n",
    "    parent_to_children = defaultdict(list)\n",
    "    seen = set()\n",
    "    has_incoming_edges = set()\n",
    "    for (parent, rel, child) in rules:\n",
    "        #print(parent, rel, child)\n",
    "        seen.add(parent)\n",
    "        seen.add(child)\n",
    "        has_incoming_edges.add(child)\n",
    "        if parent == child:\n",
    "            #print(parent, child)\n",
    "            return None\n",
    "        parent_to_children[parent].append((rel, child))\n",
    "    print(\"ramas \", parent_to_children)\n",
    "\n",
    "    # Only accept strictly connected trees.\n",
    "    roots = seen.difference(has_incoming_edges)\n",
    "    #print(\"raices \", roots)\n",
    "    if len(roots) != 1:\n",
    "        return None\n",
    "\n",
    "    root = roots.pop()\n",
    "    seen = {root}\n",
    "\n",
    "    # Step 2: check that the tree doesn't have a loop:\n",
    "    def contains_loop(node):\n",
    "        has_loop = False\n",
    "        #print(\"nodo \", parent_to_children[node])\n",
    "        for (_, child) in parent_to_children[node]:\n",
    "            if child in seen:\n",
    "                print(\"has a loop\", child)\n",
    "                return True\n",
    "            else:\n",
    "                seen.add(child)\n",
    "                has_loop = contains_loop(child)\n",
    "            if has_loop:\n",
    "                #print(\"had a loop\")\n",
    "                break\n",
    "\n",
    "        return has_loop\n",
    "\n",
    "    if contains_loop(root):\n",
    "        return None\n",
    "\n",
    "    return root, parent_to_children\n",
    "\n",
    "\n",
    "def construct_pattern(rules: List[List[str]]):\n",
    "    \"\"\"\n",
    "    Idea: add patterns to a matcher designed to find a subtree in a spacy dependency tree.\n",
    "    Rules are strictly of the form \"CHILD --rel--> PARENT\". To build this up, we add rules\n",
    "    in DFS order, so that the parent nodes have already been added to the dict for each child\n",
    "    we encounter.\n",
    "    \"\"\"\n",
    "    # Step 1: Build up a dictionary mapping parents to their children\n",
    "    # in the dependency subtree. Whilst we do this, we check that there is\n",
    "    # a single node which has only outgoing edges.\n",
    "\n",
    "    if \"dep\" in {rule[1] for rule in rules}:\n",
    "        return None\n",
    "\n",
    "    ret = check_for_non_trees(rules)\n",
    "\n",
    "    if ret is None:\n",
    "        return None\n",
    "    else:\n",
    "        root, parent_to_children = ret\n",
    "\n",
    "    def add_node(parent: str, pattern: List):\n",
    "\n",
    "        for (rel, child) in parent_to_children[parent]:\n",
    "\n",
    "            # First, we add the specification that we are looking for\n",
    "            # an edge which connects the child to the parent.\n",
    "            node = {\n",
    "                \"SPEC\": {\n",
    "                    \"NODE_NAME\": child,\n",
    "                    \"NBOR_RELOP\": \">\",\n",
    "                    \"NBOR_NAME\": parent},\n",
    "            }\n",
    "\n",
    "            # DANGER we can only have these options IF we also match ORTH below, otherwise it's torturously slow.\n",
    "            # token_pattern = {\"DEP\": {\"IN\": [\"amod\", \"compound\"]}}\n",
    "\n",
    "            # Now, we specify what attributes we want this _token_\n",
    "            # to have - in this case, we want to match a certain dependency\n",
    "            # relation specifically.\n",
    "            token_pattern = {\"DEP\": rel}\n",
    "\n",
    "            # Additionally, we can specify more token attributes. So here,\n",
    "            # if the node refers to the start or end entity, we require that\n",
    "            # the word is part of an entity (spacy syntax is funny for this)\n",
    "            # and that the word is a noun, as there are some verbs annotated as \"entities\" in medmentions.\n",
    "\n",
    "            if child in {\"START_ENTITY\", \"END_ENTITY\"}:\n",
    "                token_pattern[\"ENT_TYPE\"] = {\"NOT_IN\": [\"\"]}\n",
    "                token_pattern[\"POS\"] = \"NOUN\"\n",
    "            elif child in {\"PERSON_1\", \"PERSON_2\", \"GPE_1\", \"GPE_2\", \"ANY_1\", \"ANY_2\"}:\n",
    "                print(child)\n",
    "                #token_pattern[\"ENT_TYPE\"] = {\"NOT_IN\": [\"\"]}\n",
    "                #token_pattern[\"POS\"] = \"NOUN\"\n",
    "                #token_pattern[\"TEXT\"] = {\"REGEX\": \"*\"}\n",
    "            # If we are on part of the path which is not the start/end entity,\n",
    "            # we want the word to match. This could be made very flexible, e.g matching\n",
    "            # verbs instead, etc.\n",
    "            else:\n",
    "                token_pattern[\"LEMMA\"] = child\n",
    "\n",
    "            node[\"PATTERN\"] = token_pattern\n",
    "\n",
    "            pattern.append(node)\n",
    "            add_node(child, pattern)\n",
    "\n",
    "    pattern = [{\"SPEC\": {\"NODE_NAME\": root}, \"PATTERN\": {\"lEMMA\": root}}]\n",
    "    # pattern = [{\"SPEC\": {\"NODE_NAME\": root}, \"PATTERN\": {\"LEMMA\": root}}] # to use lemmas as root\n",
    "    add_node(root, pattern)\n",
    "\n",
    "    assert len(pattern) < 20\n",
    "    return pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc = nlp(\"Polycrates sent him on to those of Memphis, on the pretense that the were the more ancient.\")\n",
    "doc = nlp(\"Pythagoras went to Delos\")\n",
    "#doc = nlp(\"There also was born his son Pythagoras, who early manifested studiousness, but was later taken to Tyre.\")\n",
    "#doc = nlp(\"he returned to Ionia\")\n",
    "#doc = nlp(\"On sailing to Italy, Mnesarchus took the youth Pythagoras with him.\")\n",
    "#doc = nlp(\"Antiphon, in his book on illustrious Virtuous Men praises his perseverance while he was in Egypt.\")\n",
    "#doc = nlp(\"Coming to Amasis, he was given letters to the priests of Heliopolis, who sent him on to those of Memphis, on the pretense that the were the more ancient.\")\n",
    "#doc = nlp(\"In Egypt he lived with the priests.\")\n",
    "#doc = nlp(\"On the same pretense, he was sent on from Memphis to Diospolis.\")\n",
    "#doc = nlp(\"he journeyed towards Italy\")\n",
    "#doc = nlp(\"In Arabia he conferred with the King\")\n",
    "#doc = nlp(\"As a famine had arisen in Samos, Mnesarchus went thither to trade, and was naturalized there.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"2f9acc60419f4699acca84da623c8079-0\" class=\"displacy\" width=\"650\" height=\"212.0\" direction=\"ltr\" style=\"max-width: none; height: 212.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"122.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Pythagoras</tspan>\n",
       "    <tspan class=\"displacy-lemma\" dy=\"2em\" fill=\"currentColor\" x=\"50\">Pythagoras</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"122.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\">went</tspan>\n",
       "    <tspan class=\"displacy-lemma\" dy=\"2em\" fill=\"currentColor\" x=\"200\">go</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"122.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">to</tspan>\n",
       "    <tspan class=\"displacy-lemma\" dy=\"2em\" fill=\"currentColor\" x=\"350\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"122.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">Delos</tspan>\n",
       "    <tspan class=\"displacy-lemma\" dy=\"2em\" fill=\"currentColor\" x=\"500\">Delos</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2f9acc60419f4699acca84da623c8079-0-0\" stroke-width=\"2px\" d=\"M62,77.0 62,52.0 200.0,52.0 200.0,77.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2f9acc60419f4699acca84da623c8079-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,79.0 L58,71.0 66,71.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2f9acc60419f4699acca84da623c8079-0-1\" stroke-width=\"2px\" d=\"M212,77.0 212,52.0 350.0,52.0 350.0,77.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2f9acc60419f4699acca84da623c8079-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M350.0,79.0 L354.0,71.0 346.0,71.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2f9acc60419f4699acca84da623c8079-0-2\" stroke-width=\"2px\" d=\"M362,77.0 362,52.0 500.0,52.0 500.0,77.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2f9acc60419f4699acca84da623c8079-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M500.0,79.0 L504.0,71.0 496.0,71.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Pythagoras\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " went to \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Delos\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sentence_spans = list(doc.sents)\n",
    "#displacy.render(sentence_spans, style = \"dep\")\n",
    "visualise_doc(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\"to|nsubj|PERSON_1 go|prep|to to|pobj|GPE_1\"]\n",
    "#patterns = [\"bear|dobj|son son|appos|PERSON_1 bear|conj|take take|prep|to to|pobj|GPE_1\"]\n",
    "#patterns = [\"return|nsubj|PERSON_1 return|prep|to to|pobj|GPE_1\"]\n",
    "#patterns = [\"take|nsubj|PERSON_2 take|dobj|youth youth|appos|PERSON_1\"]\n",
    "#patterns = [\"take|prep|on on|pobj|sail sail|prep|to to|pobj|GPE_1\"]\n",
    "#patterns = [\"be|nsubj|PERSON_1 be|prep|ANY_1 ANY_1|pobj|GPE_1\"]\n",
    "#patterns = [\"give|nsubjpass|PERSON_1 give|dative|to to|pobj|ANY_1 ANY_1|prep|ANY_2 ANY_2|pobj|GPE_1\"]\n",
    "#patterns = [\"live|nsubj|PERSON_1 live|prep|in in|pobj|GPE_1\"]\n",
    "#patterns = [\"send|nsubjpass|PERSON_1 send|prep|from from|pobj|GPE_1 from|prep|to to|pobj|GPE_2\"]\n",
    "#pattterns =[\"return|prep|to to|pobj|GPE_1 open|nsubj|PERSON_1\"\n",
    "#patterns = [\"open|nsubj|PERSON_1 open|dobj|ANY_1 open|advcl|return return|prep|ANY_2 ANY_2|pobj|GPE_1\"]\n",
    "#patterns =[\"journey|nsubj|PERSON_1 journey|prep|ANY_1 ANY_1|pobj|GPE_1\"]\n",
    "#patterns = [\"confer|nsubj|PERSON_1 confer|prep|in in|pobj|GPE_1\"]\n",
    "#patterns = [\"go|nsubj|PERSON_1 go|advcl|arise arise|prep|in in|pobj|GPE_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ramas  defaultdict(<class 'list'>, {'to': [('nsubj', 'PERSON_1'), ('pobj', 'GPE_1')], 'go': [('prep', 'to')]})\n",
      "PERSON_1\n",
      "GPE_1\n",
      "Adding these constructed patterns  [{'SPEC': {'NODE_NAME': 'go'}, 'PATTERN': {'lEMMA': 'go'}}, {'SPEC': {'NODE_NAME': 'to', 'NBOR_RELOP': '>', 'NBOR_NAME': 'go'}, 'PATTERN': {'DEP': 'prep', 'LEMMA': 'to'}}, {'SPEC': {'NODE_NAME': 'PERSON_1', 'NBOR_RELOP': '>', 'NBOR_NAME': 'to'}, 'PATTERN': {'DEP': 'nsubj'}}, {'SPEC': {'NODE_NAME': 'GPE_1', 'NBOR_RELOP': '>', 'NBOR_NAME': 'to'}, 'PATTERN': {'DEP': 'pobj'}}]\n"
     ]
    }
   ],
   "source": [
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "\n",
    "stream = [doc]\n",
    "\n",
    "count = 0\n",
    "for pattern in patterns:\n",
    "    rules = [rule.split(\"|\") for rule in pattern.split(\" \")]\n",
    "    constructed_pattern = construct_pattern(rules)\n",
    "    count += 1\n",
    "    print(\"Adding these constructed patterns \", constructed_pattern)\n",
    "    matcher.add(\"patron \"+str(count), None, constructed_pattern)\n",
    "         \n",
    "    #print(\"Matcher full settings >\")\n",
    "    #print(\"patterns: \", matcher._patterns)\n",
    "    #print(\"keys to token\", matcher._keys_to_token)\n",
    "    #print(\"root \", matcher._root)\n",
    "    #print(\"entities \", matcher._entities)\n",
    "    #print(\"callbacks \", matcher._callbacks)\n",
    "    #print(\"nodes \", matcher._nodes)\n",
    "    #print(\"tree \", matcher._tree)\n",
    "    #print(\"< Matcher full settings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "    # salida csv\n",
    "    # based on https://stackoverflow.com/questions/33309436/python-elementtree-xml-output-to-csv\n",
    "    with open('all_relations.csv', 'w', newline='') as r:  \n",
    "        writer = csv.writer(r,  delimiter=' ', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "        #writer.writerow(['id', 'relation','subject','to','destination', 'source_text'])  # WRITING HEADERS\n",
    "        # rows vary in lenght. Therefore cannot use just one header\n",
    "        counter = 1;\n",
    "        for doc in stream:\n",
    "            matches = matcher(doc) # do the matching\n",
    "            #print(matches)\n",
    "       \n",
    "            relations = []\n",
    "            logical_relations = []\n",
    "            for match_id, token_idxs in matches:\n",
    "               for each_pattern in token_idxs: \n",
    "                   tokens = [doc[i] for i in each_pattern]\n",
    "                   heads = [doc[i].head for i in each_pattern]\n",
    "                   deps = [doc[i].dep_ for i in each_pattern]\n",
    "                   print(\"tokens>\")\n",
    "                   print(tokens)\n",
    "                   print(heads)\n",
    "                   print(deps)\n",
    "                   print(\"<\")\n",
    "                   one_row = [counter] + tokens \n",
    "                   writer.writerow(one_row) # to the csv\n",
    "                   counter += 1\n",
    "                   \n",
    "                   logical_relations.append({\"logic\":str(tokens).strip('[]')}) # adding the logical relation to the db too\n",
    "                 \n",
    "                   branch = matcher._tree[match_id] # realnente es una lista de branches de este id\n",
    "                   print(branch)\n",
    "                   \n",
    "                   for k in branch[0]:\n",
    "                       for rel, j in branch[0][k]:\n",
    "                           print(tokens[k],\"--\",deps[j],rel,tokens[j])\n",
    "                           relations.append({\"child\": int(each_pattern[j]), \"head\": int(each_pattern[k]), \"label\": deps[j]})             \n",
    "\n",
    "  #        print(relations) \n",
    "            print(logical_relations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
